# ğŸ¨ Visual Guide â€” Lab 5 Multi-Agent System

Every concept in this lab explained with diagrams. Read this BEFORE or
ALONGSIDE the scripts â€” it will make everything click.

---

## 1. The Big Picture â€” What Are We Building?

```
  You type a question
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Planner   â”‚   â† "What should I search for?"
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚  search query
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Retriever  â”‚   â† "Let me look that up."     (calls DuckDuckGo)
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚  raw results
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”
  â”‚   Router    â”‚â”€â”€â”€â”€â–¶â”‚ END â”‚   â† "Did that work?"
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”˜     If not â†’ loop back to Planner
         â”‚  (yes, it worked)
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Summariser  â”‚   â† "Let me clean this up for you."
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚  polished answer
         â–¼
     You read it
```

---

## 2. LangChain vs LangGraph vs OpenAI SDK â€” When to Use Which

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                        OpenAI SDK                           â”‚
  â”‚                                                             â”‚
  â”‚   client.chat.completions.create(â€¦)                         â”‚
  â”‚                                                             â”‚
  â”‚   Use when:  You just want to call GPT-4.                   â”‚
  â”‚              No agents.  No tools.  No memory.              â”‚
  â”‚              The simplest possible LLM call.                â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚  LangChain wraps this
                              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                       LangChain                             â”‚
  â”‚                                                             â”‚
  â”‚   ChatOpenAI(â€¦)           â†’ swappable LLM wrapper           â”‚
  â”‚   PromptTemplate(â€¦)       â†’ reusable prompt with variables  â”‚
  â”‚   LLMChain(â€¦)             â†’ prompt + LLM glued together     â”‚
  â”‚   ConversationBufferMemory â†’ stores conversation history    â”‚
  â”‚   Tool(â€¦)                 â†’ wraps any function for the LLM  â”‚
  â”‚                                                             â”‚
  â”‚   Use when:  You want ONE chain of steps.                   â”‚
  â”‚              You want to swap LLM providers easily.         â”‚
  â”‚              You want memory or tool wrappers.              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚  LangGraph builds on this
                              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                       LangGraph                             â”‚
  â”‚                                                             â”‚
  â”‚   StateGraph(â€¦)           â†’ the graph container             â”‚
  â”‚   .add_node(name, fn)     â†’ register an agent function      â”‚
  â”‚   .add_edge(a, b)         â†’ "after a, run b"                â”‚
  â”‚   .add_conditional_edge() â†’ "after a, DECIDE what's next"   â”‚
  â”‚   .compile()              â†’ lock and validate the graph     â”‚
  â”‚   .invoke(state)          â†’ run the whole pipeline          â”‚
  â”‚                                                             â”‚
  â”‚   Use when:  You have MULTIPLE agents.                      â”‚
  â”‚              You need branching or looping.                 â”‚
  â”‚              You want structured, debuggable workflows.     â”‚
  â”‚              THIS IS WHAT WE USE IN THIS LAB.               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Hierarchy:   OpenAI SDK  âŠ‚  LangChain  âŠ‚  LangGraph
               (bare bones)              (full power)
```

---

## 3. What Is a "Chain"? (LangChain's core unit)

```
  INPUT
    â”‚
    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ PromptTemplateâ”‚   "You are a helpful assistant. Answer: {question}"
  â”‚  (fills in    â”‚        â†“ fills {question} with the actual input
  â”‚   variables)  â”‚   "You are a helpful assistant. Answer: What is AI?"
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   ChatOpenAI â”‚   Sends the prompt to GPT-4 â†’ gets a response
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
  OUTPUT (the LLM's answer)

  A Chain is just these two boxes connected.  LLMChain does this for you.
```

---

## 4. What Is a "Graph"? (LangGraph's core unit)

```
  A CHAIN (linear â€” no decisions):

    A  â”€â”€â–¶  B  â”€â”€â–¶  C  â”€â”€â–¶  END
    (can only go forward)


  A GRAPH (can branch and loop):

              â”Œâ”€â”€â”€â”€â”€â”€â”
    A  â”€â”€â–¶  B  â”€â”€â–¶  C  â”€â”€â–¶  END
              â”‚              â–²
              â”‚ (retry)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (can go backward if B fails!)


  LangGraph is a GRAPH, not a chain.
  That is its entire reason for existing.
```

---

## 5. What Is "State"? (The agents' shared clipboard)

```
  State is a dictionary that flows through every node.
  Each agent reads what it needs and writes what it produces.

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  state = {                                          â”‚
  â”‚    "input":           "What is Mars exploration?"   â”‚  â† set by user
  â”‚    "planner_output":  "Mars exploration 2025 news"  â”‚  â† set by Planner
  â”‚    "retrieved_info":  "NASA announced â€¦"            â”‚  â† set by Retriever
  â”‚    "final_output":    "Based on reports â€¦"          â”‚  â† set by Summariser
  â”‚    "retries":         0                             â”‚  â† retry counter
  â”‚  }                                                  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Think of it as a baton in a relay race.
  Each runner (agent) grabs it, adds their contribution, passes it on.
```

---

## 6. What Is a "Tool"?

```
  A Tool = a Python function + a name + a description.

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Tool(                                          â”‚
  â”‚    name        = "WebSearch"                    â”‚  â† identifier
  â”‚    func        = search.run                     â”‚  â† the actual function
  â”‚    description = "Searches the web for info"    â”‚  â† LLM reads THIS
  â”‚  )                                              â”‚     to know when to use it
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  In our lab, the Retriever calls search.run(query) directly.
  The Tool wrapper is shown for completeness â€” in more advanced setups
  the LLM itself decides which tool to call.

  Other tools you could add later:
    â€¢ Calculator      â†’ math questions
    â€¢ CodeExecutor    â†’ run Python snippets
    â€¢ DatabaseQuery   â†’ SQL lookups
    â€¢ RAG Retriever   â†’ your own vector database (from Lab 4!)
```

---

## 7. What Is "Memory"?

```
  LLMs forget everything between calls.  Memory fixes that.

  Without memory:
    Call 1: "What is AI?"        â†’ "AI is â€¦"
    Call 2: "Tell me more."      â†’ "I don't know what you mean."  âŒ

  With memory:
    Call 1: "What is AI?"        â†’ "AI is â€¦"
           (memory stores both messages)
    Call 2: "Tell me more."      â†’ "Sure!  As I mentioned, AI â€¦"  âœ…

  ConversationBufferMemory stores every Human + AI message.
  In our graph, each agent logs its work to memory so the whole
  conversation is traceable at the end.
```

---

## 8. The Conditional Edge â€” How Retry Works

```
  After the Retriever runs, the Router checks the results:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                                      â”‚
  â”‚   Retriever done                                     â”‚
  â”‚       â”‚                                              â”‚
  â”‚       â–¼                                              â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
  â”‚   â”‚   Router   â”‚   checks: are results useful?       â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
  â”‚         â”‚                                            â”‚
  â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                       â”‚
  â”‚    â”‚         â”‚                                       â”‚
  â”‚    â–¼         â–¼                                       â”‚
  â”‚  GOOD      BAD                                       â”‚
  â”‚    â”‚         â”‚                                       â”‚
  â”‚    â–¼         â–¼                                       â”‚
  â”‚ Summariser  Planner  â† retry with a different query  â”‚
  â”‚    â”‚         â”‚                                       â”‚
  â”‚    â–¼         â”‚                                       â”‚
  â”‚   END        â””â”€â”€ (loop back, try again)              â”‚
  â”‚                                                      â”‚
  â”‚   After MAX_RETRIES (2) bad results â†’ END with error â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  The Router is just a function:
      def router(state) -> str:
          if results_are_bad:
              return "planner"    # loop
          else:
              return "summarize"  # continue
```

---

## 9. How Each Agent's Prompt Differs

```
  Each agent gets a FOCUSED prompt â€” that is why they work well.

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PLANNER prompt:                                             â”‚
  â”‚  "Your ONLY job is to rewrite the question into a search     â”‚
  â”‚   query.  Do NOT answer â€” only produce the query."           â”‚
  â”‚                                                              â”‚
  â”‚  Why: Forces the LLM to think about searchability, not       â”‚
  â”‚       to answer directly.                                    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  RETRIEVER:  No LLM prompt needed!                           â”‚
  â”‚  It just calls search.run(query) â€” a Python function.        â”‚
  â”‚                                                              â”‚
  â”‚  Why: Searching is a mechanical action, not a thinking one.  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  SUMMARISER prompt:                                          â”‚
  â”‚  "Synthesise these raw results into a clear, concise answer  â”‚
  â”‚   (3-5 sentences)."                                          â”‚
  â”‚                                                              â”‚
  â”‚  Why: Forces the LLM to distil and organise â€” exactly what   â”‚
  â”‚       it is best at.                                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Demo Mode vs Live Mode

```
  Every script has TWO paths:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚     LIVE MODE       â”‚     â”‚     DEMO MODE       â”‚
  â”‚  (API key present)  â”‚     â”‚  (no API key)       â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚ LLM   â†’ real GPT-4  â”‚     â”‚ LLM   â†’ canned text â”‚
  â”‚ Search â†’ DuckDuckGo â”‚     â”‚ Search â†’ fake data  â”‚
  â”‚ Output â†’ real answerâ”‚     â”‚ Output â†’ demo text  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  Demo mode teaches you the STRUCTURE and FLOW.
  Live mode gives you REAL answers.

  Both paths use the exact same graph logic.
```

---

## 11. Lab 4 + Lab 5 = Unstoppable Combo

```
  Lab 4 built a knowledge base:
      Documents â†’ Embeddings â†’ FAISS / Pinecone / RDF

  Lab 5 built an agent system:
      Planner â†’ Retriever â†’ Summariser

  Combined:
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Planner â”‚â”€â”€â”€â”€â–¶â”‚  Retriever                   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”œâ”€â”€ DuckDuckGo (web)      â”‚
                       â”‚    â”œâ”€â”€ FAISS (local vectors) â”‚
                       â”‚    â”œâ”€â”€ Pinecone (cloud)      â”‚
                       â”‚    â””â”€â”€ RDF Graph (structure) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     Summariser       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  The Retriever can call ANY tool.  Swap DuckDuckGo for your Lab 4
  RAG pipeline and you have a hybrid-retrieval multi-agent system!
```

---

## 12. Script-by-Script Summary

| Script                         | What it teaches                          | Key takeaway                      |
| ------------------------------ | ---------------------------------------- | --------------------------------- |
| `01_concepts.py`               | Chain, Graph, Agent, State, Tool, Memory | Mental model                      |
| `02_setup_tools_and_memory.py` | Real LangChain objects                   | LLM + Search + Memory in 10 lines |
| `03_define_agents.py`          | Write agent functions                    | `fn(state) â†’ dict` is the pattern |
| `04_build_graph.py`            | Wire agents into LangGraph               | Nodes + Edges + compile()         |
| `05_conditional_edge.py`       | Branching / retry                        | Router function decides next node |
| `06_full_interactive.py`       | Interactive CLI                          | The finished product              |

---

## 13. Glossary

| Term                 | What it means                                         |
| -------------------- | ----------------------------------------------------- |
| **Agent**            | A function that does one job (Planner, Retriever, â€¦)  |
| **Chain**            | A linear sequence: prompt â†’ LLM â†’ output              |
| **Compile**          | Lock the graph and validate it (no missing nodes)     |
| **Conditional edge** | An edge whose destination is decided at runtime       |
| **Edge**             | An arrow between two nodes ("after A, run B")         |
| **END**              | The special node that stops the graph                 |
| **Entry point**      | The first node the graph runs                         |
| **Invoke**           | Run the compiled graph with an input                  |
| **LLM**              | Large Language Model (GPT-4, etc.)                    |
| **Memory**           | Stored conversation history                           |
| **Node**             | A single agent function in the graph                  |
| **Prompt**           | The text you send to the LLM                          |
| **Router**           | A function that decides which node runs next          |
| **State**            | The shared dictionary flowing through every node      |
| **Tool**             | A wrapped Python function the LLM / agent can call    |
| **TypedDict**        | A Python class that defines which keys state can have |
