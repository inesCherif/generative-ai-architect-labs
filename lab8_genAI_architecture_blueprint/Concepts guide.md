# Lab 8: Architecture Concepts Guide

Everything you need to know about designing GenAI systems.

---

## ğŸ“š Part 1: What is System Architecture?

### Simple Definition

**System Architecture** = Blueprint for how software components work together

Think of it like:

- **Building Architecture** â†’ Blueprint shows rooms, plumbing, electrical
- **System Architecture** â†’ Diagram shows services, databases, data flow

### Why Architecture Matters

**Without Architecture:**

```
âŒ Components don't fit together
âŒ Performance bottlenecks
âŒ Security vulnerabilities
âŒ Hard to scale
âŒ Difficult to maintain
```

**With Architecture:**

```
âœ… Clear component responsibilities
âœ… Optimized data flow
âœ… Security by design
âœ… Scalable from day one
âœ… Easy to explain and maintain
```

---

## ğŸ—ï¸ Part 2: GenAI Architecture Components

### Layer 1: User Interface (Frontend)

**What it is:** How users interact with your AI system

**Options:**

- **Web App** - Streamlit, Gradio, React
- **Mobile App** - React Native, Flutter
- **Chat Interface** - Slack bot, Discord bot
- **API Only** - No UI, just endpoints

**When to use what:**

- Internal tool â†’ Streamlit (fast to build)
- Customer-facing â†’ React (professional)
- Team collaboration â†’ Slack/Discord bot
- Integration â†’ API only

**Example:**

```python
# Streamlit chat interface
import streamlit as st

st.title("AI Assistant")
user_input = st.text_input("Ask me anything:")
if user_input:
    response = ai_pipeline(user_input)
    st.write(response)
```

---

### Layer 2: API Gateway

**What it is:** Entry point that routes requests to services

**Why you need it:**

- Authentication (who is this?)
- Rate limiting (prevent abuse)
- Routing (which service handles this?)
- Monitoring (track usage)

**Options:**

- **AWS API Gateway** - Managed, scales automatically
- **Kong** - Open source, flexible
- **FastAPI** - Simple, Python-native (what we used in Lab 7)

**Example Flow:**

```
User Request
    â†“
API Gateway
    â†“ (checks auth token)
    â†“ (checks rate limit)
    â†“ (routes based on path)
    â†“
Backend Service
```

---

### Layer 3: LLM (Large Language Model)

**What it is:** The AI brain that generates responses

**Options:**

**1. OpenAI GPT-4**

- âœ… Most capable
- âœ… Easy API
- âŒ Expensive
- âŒ Data sent to OpenAI

**2. Anthropic Claude**

- âœ… Long context (200K tokens)
- âœ… Strong reasoning
- âŒ Expensive
- âŒ Data sent to Anthropic

**3. Open Source (Llama, Mistral)**

- âœ… Private (your infrastructure)
- âœ… Customizable
- âŒ Need GPU infrastructure
- âŒ More complex to deploy

**4. Azure OpenAI**

- âœ… Enterprise features
- âœ… Data stays in your cloud
- âŒ More expensive
- âŒ Requires Azure setup

**When to use what:**

- Prototype â†’ OpenAI GPT-4 (easiest)
- Production (sensitive data) â†’ Azure OpenAI or self-hosted
- Cost-sensitive â†’ Open source models
- Long documents â†’ Claude

---

### Layer 4: RAG Components

**What it is:** System for retrieving relevant knowledge

**Component 4a: Vector Database**

**What it does:** Stores document embeddings for semantic search

**Options:**

- **Pinecone** - Managed, easy, expensive
- **Weaviate** - Open source, feature-rich
- **Chroma** - Simple, local, free
- **FAISS** - Facebook's library, fast

**When to use:**

- Need semantic similarity search
- Large document corpus
- "Find similar" queries

**Example:**

```python
# Store documents
vectordb.add(documents, embeddings)

# Search
results = vectordb.search("How to treat headaches?", k=5)
```

**Component 4b: Knowledge Graph**

**What it does:** Stores structured relationships (what you did in Lab 7!)

**Options:**

- **Neo4j** - Popular graph database
- **Stardog** - RDF/SPARQL focus
- **Apache Jena Fuseki** - What we used in Lab 7

**When to use:**

- Complex relationships matter
- Need reasoning
- Domain has hierarchies

**Example:**

```sparql
SELECT ?treatment ?mechanism
WHERE {
    ?treatment treats ?disease .
    ?treatment hasMechanism ?mechanism .
}
```

---

### Layer 5: Agent Orchestration (Optional)

**What it is:** Coordinates multiple AI agents to solve complex tasks

**Why you might need it:**

- Multi-step workflows
- Need to use multiple tools
- Complex reasoning required

**Options:**

**1. LangChain**

- âœ… Most popular
- âœ… Lots of integrations
- âŒ Complex API

**2. LangGraph**

- âœ… State management
- âœ… Explicit control flow
- âŒ Newer, fewer examples

**3. CrewAI**

- âœ… Multi-agent focus
- âœ… Role-based agents
- âŒ Less flexible

**4. AutoGen**

- âœ… Microsoft-backed
- âœ… Conversational agents
- âŒ Still evolving

**Example Use Case:**

```
User: "Analyze this contract and schedule a review meeting"

Agent 1 (Analyst): Reads contract, identifies risks
    â†“
Agent 2 (Summarizer): Creates executive summary
    â†“
Agent 3 (Scheduler): Checks calendars, books meeting
    â†“
Final Response: "Found 3 risks. Meeting scheduled for Tuesday."
```

---

### Layer 6: Data Storage

**What it is:** Where you store application data

**Options:**

**Relational DB (PostgreSQL, MySQL)**

- âœ… Structured data
- âœ… Transactions
- âŒ Not for unstructured text

**Document DB (MongoDB)**

- âœ… Flexible schema
- âœ… JSON documents
- âŒ No complex joins

**Object Storage (S3)**

- âœ… Files, images, documents
- âœ… Cheap, scalable
- âŒ No querying

**When to use what:**

```
User accounts, orders     â†’ PostgreSQL
Chat history, logs        â†’ MongoDB
PDFs, images, videos      â†’ S3
Document embeddings       â†’ Vector DB
Knowledge relationships   â†’ Graph DB
```

---

### Layer 7: Deployment & Infrastructure

**What it is:** Where your code runs

**Options:**

**1. Cloud Functions (Serverless)**

- âœ… Auto-scales
- âœ… Pay per use
- âŒ Cold starts
- âŒ Limited by timeout

**2. Containers (Docker + K8s)**

- âœ… Full control
- âœ… No timeouts
- âŒ More complex
- âŒ Need to manage scaling

**3. Managed Services**

- AWS Fargate - Run containers without managing servers
- Azure Container Apps - Similar to Fargate
- Google Cloud Run - Serverless containers

**When to use what:**

- Simple API â†’ Cloud Functions
- Complex workflows â†’ Containers
- Need GPUs â†’ EC2/Compute instances
- Best balance â†’ Fargate/Cloud Run

---

### Layer 8: Monitoring & Observability

**What it is:** Track system health and performance

**What to monitor:**

- **Latency** - How long do requests take?
- **Errors** - What's failing?
- **Token usage** - LLM cost tracking
- **User satisfaction** - Thumbs up/down
- **System resources** - CPU, memory, disk

**Tools:**

- **Prometheus + Grafana** - Open source, flexible
- **CloudWatch (AWS)** - Managed, integrated
- **Datadog** - Premium, powerful
- **LangSmith** - LLM-specific monitoring

**Example Metrics:**

```python
# Track in your code
track_metric("llm_latency", duration_ms)
track_metric("tokens_used", token_count)
track_metric("user_satisfaction", thumbs_up)
```

---

## ğŸ¨ Part 3: Common Architecture Patterns

### Pattern 1: Simple RAG

**Use Case:** Basic Q&A bot

```
User Question
    â†“
Retrieve relevant docs (Vector DB)
    â†“
Add to prompt
    â†“
LLM generates answer
    â†“
Return response
```

**Pros:**

- âœ… Simple to build
- âœ… Easy to understand
- âœ… Fast to iterate

**Cons:**

- âŒ Limited reasoning
- âŒ No multi-step tasks
- âŒ Single knowledge source

---

### Pattern 2: Multi-Source RAG

**Use Case:** Research assistant, comprehensive Q&A

```
User Question
    â†“
Query multiple sources in parallel:
    - Vector DB (semantic search)
    - Graph DB (relationship queries)
    - SQL DB (structured data)
    â†“
Combine & rank results
    â†“
LLM generates answer
```

**Pros:**

- âœ… Comprehensive answers
- âœ… Multiple perspectives
- âœ… Rich context

**Cons:**

- âŒ More complex
- âŒ Slower
- âŒ Need to merge results

---

### Pattern 3: Agentic Workflow

**Use Case:** Complex tasks, multi-step reasoning

```
User Task
    â†“
Planner Agent: Creates execution plan
    â†“
Executor Agents: Each handles a step
    - Retriever: Gets information
    - Analyzer: Processes data
    - Summarizer: Creates output
    â†“
Coordinator: Combines results
    â†“
Final output
```

**Pros:**

- âœ… Handles complex tasks
- âœ… Can use tools
- âœ… Self-correcting

**Cons:**

- âŒ Expensive (many LLM calls)
- âŒ Unpredictable
- âŒ Hard to debug

---

### Pattern 4: Hybrid (Best of All)

**Use Case:** Production systems, enterprise applications

```
User Request
    â†“
API Gateway (auth, routing)
    â†“
Request Classifier: Determines complexity
    â†“
Simple query â†’ Simple RAG (fast, cheap)
Complex query â†’ Multi-source RAG + Agents
    â†“
Response with source citations
    â†“
Monitoring & feedback loop
```

**Pros:**

- âœ… Optimized for each query type
- âœ… Cost-efficient
- âœ… Scalable

**Cons:**

- âŒ Most complex to build
- âŒ More components to maintain

---

## ğŸ“Š Part 4: Making Architecture Decisions

### Decision Framework

For each component, ask:

1. **What problem does it solve?**
   - If no clear problem â†’ Don't add it

2. **What are the alternatives?**
   - Compare 2-3 options

3. **What are the trade-offs?**
   - Cost vs. features
   - Complexity vs. control
   - Speed vs. accuracy

4. **What's the simplest solution?**
   - Start simple, add complexity only when needed

### Example Decision Process

**Question:** Should we use a vector database?

**Analysis:**

- Problem: Need to search 10,000 documents for relevant context
- Alternatives:
  1. Keyword search (fast, but misses semantics)
  2. Vector DB (semantic, but costs money)
  3. Read all docs each time (accurate, but way too slow)
- Trade-offs:
  - Vector DB adds cost but needed for quality
- Decision: Yes, use vector DB (Chroma for prototype, Pinecone for production)

---

## ğŸ¯ Part 5: Architecture Best Practices

### 1. Start Simple

**Don't:**

```
âŒ Start with 10 microservices
âŒ Use every tool and framework
âŒ Over-engineer for scale you don't have
```

**Do:**

```
âœ… Start with monolith
âœ… Add complexity only when needed
âœ… Prove value first, scale later
```

---

### 2. Decouple Components

**Bad (Tightly Coupled):**

```python
# UI directly calls LLM
response = openai.chat(user_input)
```

**Good (Decoupled):**

```python
# UI â†’ API â†’ Service â†’ LLM
response = api_client.query(user_input)
```

**Why?**

- Easy to swap LLM providers
- Can add caching layer
- Testable in isolation

---

### 3. Design for Observability

**Build monitoring in from day one:**

```python
@track_metrics
def generate_response(query):
    start = time.time()

    # Retrieve
    docs = retrieve(query)
    log_metric("retrieval_time", time.time() - start)

    # Generate
    response = llm.generate(query, docs)
    log_metric("generation_time", time.time() - start)
    log_metric("tokens_used", response.tokens)

    return response
```

---

### 4. Handle Failures Gracefully

**LLMs can fail!** Design for it:

```python
def generate_with_fallback(query):
    try:
        # Try GPT-4
        return gpt4.generate(query)
    except RateLimitError:
        # Fall back to GPT-3.5
        return gpt35.generate(query)
    except Exception:
        # Return helpful error
        return "I'm having trouble right now. Please try again."
```

---

### 5. Cost Management

**LLM costs add up fast!**

**Strategies:**

1. **Cache responses** - Same question = Same answer
2. **Use cheaper models** - GPT-3.5 for simple tasks
3. **Truncate context** - Only include relevant parts
4. **Batch requests** - Process multiple at once
5. **Monitor usage** - Set alerts on spend

**Example:**

```python
# Check cache first
cached = cache.get(query_hash)
if cached:
    return cached  # Free!

# Only call LLM if not cached
response = llm.generate(query)
cache.set(query_hash, response)
```

---

## ğŸ“ Part 6: How to Draw Architecture Diagrams

### Diagramming Best Practices

**1. Use Standard Symbols**

- Rectangles = Services/Components
- Cylinders = Databases
- Clouds = External services
- Arrows = Data flow

**2. Left-to-Right or Top-to-Bottom Flow**

```
User â†’ Frontend â†’ API â†’ Backend â†’ Database
```

**3. Group Related Components**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Layer                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚Vectorâ”‚  â”‚Graph â”‚        â”‚
â”‚  â”‚  DB  â”‚  â”‚  DB  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**4. Label Everything**

- Component names
- Connection types (REST, gRPC, etc.)
- Technologies used

**5. Include Legends**

```
Solid line   = Synchronous call
Dashed line  = Asynchronous
Red arrow    = Error path
```

---

### Tools for Diagramming

**1. draw.io (Recommended)**

- âœ… Free
- âœ… Works in browser
- âœ… Lots of shapes
- âœ… Export to PNG/PDF

**2. Mermaid (Code-based)**

- âœ… Version control friendly
- âœ… Fast for simple diagrams
- âœ… Renders in GitHub
- âŒ Less flexible

**3. Lucidchart (Premium)**

- âœ… Collaborative
- âœ… Professional templates
- âŒ Costs money

**4. Excalidraw (Sketchy style)**

- âœ… Quick sketches
- âœ… Hand-drawn aesthetic
- âŒ Less professional

---

## ğŸ’¼ Part 7: Communicating Architecture to Stakeholders

### To Executives (Non-Technical)

**Focus on:**

- Business value
- ROI (return on investment)
- Time to market
- Risk mitigation

**Example:**

```
"This architecture will:
- Reduce customer support costs by 40%
- Answer 80% of questions automatically
- Launch in 6 weeks
- Scale to handle growth"
```

**Use analogies:**

```
âŒ "We'll use a graph database with SPARQL"
âœ… "Think of it like a smart filing system that understands relationships"
```

---

### To Engineers (Technical)

**Focus on:**

- Technology choices
- Scalability
- Trade-offs
- Implementation details

**Example:**

```
"Architecture decisions:
1. FastAPI for API (async, type-safe)
2. Pinecone for vectors (managed, scales)
3. PostgreSQL for app data (ACID, familiar)
4. Docker + Fargate (containers, serverless)

Trade-offs:
- Pinecone costs more but saves dev time
- Fargate simpler than K8s but less control"
```

---

### To Product Managers

**Focus on:**

- Features enabled
- Timeline
- Resource needs
- Risks and mitigation

**Example:**

```
"Architecture supports:
âœ… Feature 1: Smart search (Week 2)
âœ… Feature 2: Recommendations (Week 4)
âœ… Feature 3: Analytics (Week 6)

Risks:
- LLM cost could exceed budget
  â†’ Mitigation: Caching + cheaper model fallback
```

---

## ğŸ“ Summary: Key Takeaways

### Architecture is About Trade-offs

Every decision involves trade-offs:

- Simple vs. Powerful
- Fast vs. Accurate
- Cheap vs. Feature-rich
- Flexible vs. Performant

**Good architects:**

- Understand the options
- Know the trade-offs
- Make informed decisions
- Document the reasoning

---

### Start Simple, Then Scale

**Phase 1: Prototype**

- FastAPI + OpenAI + Chroma
- Proves concept quickly

**Phase 2: Production**

- Add auth, monitoring, caching
- Switch to Pinecone for scale

**Phase 3: Enterprise**

- Multi-region deployment
- Advanced security
- Custom models

---

### Understand Your Use Case

Different use cases need different architectures:

**Simple Q&A:**

- Vector DB + LLM = Done

**Complex Analysis:**

- Multi-source RAG + Agents

**Real-time Chat:**

- Streaming responses
- Low latency critical

**Batch Processing:**

- Process millions of docs
- Throughput over latency

---

**You're now ready to design your own GenAI architecture!** ğŸš€
